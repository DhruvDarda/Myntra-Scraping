{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Transformer from scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhruvDarda/Persuasive-Text-Generation-in-Fashion/blob/main/Transformer_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.legacy import data\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch import Tensor \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from rouge import Rouge"
      ],
      "id": "3539f61f-fe7d-4428-b074-327a883f7f6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pj321J54D9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1741fb49-f587-4fea-ebeb-2aee863d7fe9"
      },
      "source": [
        "#%pip install numpy -U\n",
        "import pandas as pd\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "%cd /content/gdrive/My Drive/'NLP PROJECT'\n",
        "\n",
        "writer = SummaryWriter('Transformer/largerwithdecoder')"
      ],
      "id": "2Pj321J54D9O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/My Drive/NLP PROJECT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx-O0kkA3JKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "afa4c875-d387-410e-8bc0-58968408b229"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "inputs = open('inputs_final1.txt').read().split('\\n')\n",
        "outputs = open('outputs_final.txt').read().split('\\n')\n",
        "inputs = inputs[:min(len(inputs), len(outputs))]\n",
        "outputs = outputs[:min(len(inputs), len(outputs))]\n",
        "\n",
        "print(len(set(outputs)), len(outputs))\n",
        "\n",
        "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "for i in range(len(inputs)):\n",
        "  new_words = tokenizer.tokenize(inputs[i])\n",
        "  inputs[i] = ' '.join(new_words)\n",
        "\n",
        "raw_data = {'inputs':[line for line in inputs],\n",
        "            'outputs': [line for line in outputs]}\n",
        "df = pd.DataFrame(raw_data, columns = ['inputs', 'outputs'])\n",
        "print(df.head())\n",
        "\n",
        "print(max(inputs))\n",
        "\n",
        "train, test = train_test_split(df, test_size = 0.2)\n",
        "\n",
        "train.to_csv('train.csv', index = False)\n",
        "test.to_csv('test.csv', index = False)"
      ],
      "id": "Zx-O0kkA3JKH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "8643 35273\n",
            "                                              inputs                                            outputs\n",
            "0  Women Navy Blue amp Rust Orange Printed Straig...  This fashionable kurta from anayna will take y...\n",
            "1  Green amp Gold Toned Silk Blend Embroidered Sa...  This fashionable kurta from anayna will take y...\n",
            "2  Women Green amp Pink Embroidered Straight Kurt...  Comfortable and stylish, this kurta from Vbuyz...\n",
            "3  Dusty Pink Embroidered Semi Stitched Lehenga a...  Comfortable and stylish, this kurta from Vbuyz...\n",
            "4  Women Pink Ethnic Motifs Yoke Design Regular G...  Comfortable and stylish, this kurta from Vbuyz...\n",
            "women Pink amp White Ethnic Motifs Hand Printed Bell Sleeves Cotton A Line Kurta Maaesa Pink white hand ethnic motifs hand printed kurta Three quarter bell sleeves Round neck with mock button placket closure Calf length Straight hem A line shape with regular style Machine weave regular cotton Disclaimer The product might have slight shade print and embroidery variation as all our products are hand dyed printed and hand work 50 polyester 50 silk Machine wash\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-80c6d791a9f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sv9IPUH_E_e"
      },
      "source": [
        "SOS_WORD = '<sos>'\n",
        "EOS_WORD = '<eos>'\n",
        "BLANK_WORD = \"<blank>\"\n",
        "MAX_LEN = 70\n",
        "SRC = data.Field(sequential = True, lower = False, pad_token= BLANK_WORD,fix_length=MAX_LEN,init_token = SOS_WORD, eos_token = EOS_WORD)\n",
        "TRG = data.Field(sequential = True, lower = False, pad_token= BLANK_WORD,fix_length=MAX_LEN,init_token = SOS_WORD, eos_token = EOS_WORD)\n",
        "fields = ((\"SPEC\", SRC), (\"PERS\", TRG))\n",
        "\n",
        "train_data, test_data = data.TabularDataset.splits(path='./', train='train.csv', test= 'test.csv',\\\n",
        "                                            format='csv', fields=fields, skip_header=True)"
      ],
      "id": "9sv9IPUH_E_e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZaDh83eEcpU"
      },
      "source": [
        "SRC.build_vocab(train_data, test_data)\n",
        "TRG.build_vocab(train_data, test_data)"
      ],
      "id": "7ZaDh83eEcpU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
        "tags": []
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
        "    Daniel Melchor: https://medium.com/p/c80afbc9ffb1/\n",
        "    \"\"\"\n",
        "    # Constructor\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_tokens_inp,\n",
        "        num_tokens_out,\n",
        "        dim_model,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dropout_p,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # INFO\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.dim_model = dim_model\n",
        "\n",
        "        # LAYERS\n",
        "        self.positional_encoder = PositionalEncoding(\n",
        "            dim_model=dim_model, dropout_p=dropout_p, max_len=70\n",
        "        )\n",
        "        self.embedding1 = nn.Embedding(num_tokens_inp, dim_model)\n",
        "        self.embedding2 = nn.Embedding(num_tokens_out, dim_model)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=dim_model,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dropout=dropout_p,\n",
        "        )\n",
        "        self.out = nn.Linear(dim_model, num_tokens_out)\n",
        "        \n",
        "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
        "        # Src size must be (batch_size, src sequence length)\n",
        "        # Tgt size must be (batch_size, tgt sequence length)\n",
        "\n",
        "        src_pad_mask = self.make_len_mask(src)\n",
        "        tgt_pad_mask = self.make_len_mask(tgt)\n",
        "\n",
        "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
        "        src = self.embedding1(src) * math.sqrt(self.dim_model)\n",
        "        tgt = self.embedding2(tgt) * math.sqrt(self.dim_model)\n",
        "        src = self.positional_encoder(src)\n",
        "        tgt = self.positional_encoder(tgt)\n",
        "        \n",
        "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
        "        # to obtain size (sequence length, batch_size, dim_model),\n",
        "        src = src.permute(1,0,2)\n",
        "        tgt = tgt.permute(1,0,2)\n",
        "\n",
        "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
        "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
        "        out = self.out(transformer_out)\n",
        "        \n",
        "        return out #(batch_size,sequence_length,French_vocab)\n",
        "      \n",
        "    def make_len_mask(self, inp):\n",
        "        #print(inp.reshape(1,2))\n",
        "        return (inp == 0)#.transpose(0, 1)\n",
        "\n",
        "    def get_tgt_mask(self, size) -> torch.tensor:\n",
        "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
        "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
        "        \n",
        "        # EX for size=5:\n",
        "        # [[0., -inf, -inf, -inf, -inf],\n",
        "        #  [0.,   0., -inf, -inf, -inf],\n",
        "        #  [0.,   0.,   0., -inf, -inf],\n",
        "        #  [0.,   0.,   0.,   0., -inf],\n",
        "        #  [0.,   0.,   0.,   0.,   0.]]\n",
        "        \n",
        "        return mask\n",
        "    \n",
        "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
        "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
        "        # [False, False, False, True, True, True]\n",
        "        return (matrix == pad_token)"
      ],
      "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnFTvUudDL9W"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device=\"cpu\""
      ],
      "id": "FnFTvUudDL9W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbZuqSVOC6Q9"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device, sort_key = lambda x: len(x.SPEC),\n",
        "    sort_within_batch=True)"
      ],
      "id": "mbZuqSVOC6Q9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c72c2ada-2106-4505-82f5-086e518080a5",
        "tags": []
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, dim_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "        # max_len determines how far the position can have an effect on a token (window)\n",
        "        \n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, dim_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ],
      "id": "c72c2ada-2106-4505-82f5-086e518080a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "\n",
        "model = Transformer(\n",
        "    num_tokens_inp=INPUT_DIM,num_tokens_out=OUTPUT_DIM, dim_model=200, num_heads=4, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1\n",
        ").to(device)\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXQwsyWvpdn1"
      },
      "source": [
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(PATH, model, optimizer):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(PATH)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "    epoch = checkpoint['epoch']\n",
        "    return epoch, model, optimizer"
      ],
      "id": "UXQwsyWvpdn1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
      },
      "source": [
        "def train_loop(model, opt, loss_fn, dataloader, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    path = %pwd\n",
        "    PATH = os.path.join(path, 'my_checkpoint.pth.tar')\n",
        "    #epoch, model, opt = load_checkpoint(PATH, model, opt)\n",
        "    for batch in tqdm(dataloader):\n",
        "        X, y = batch.SPEC.T, batch.PERS.T\n",
        "\n",
        "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "        y_input = y[:,:-1]\n",
        "        y_expected = y[:,1:]\n",
        "        \n",
        "        # Get mask to mask out the next words\n",
        "        sequence_length = y_input.size(1)\n",
        "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "        # Standard training except we pass in y_input and tgt_mask\n",
        "        pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "        # Permute pred to have batch size first again\n",
        "        pred = pred.permute(1, 2, 0)      \n",
        "        loss = loss_fn(pred, y_expected)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    \n",
        "        total_loss += loss.detach().item()\n",
        "\n",
        "    checkpoint = {\"state_dict\" : model.state_dict(), \"optimizer\" : opt.state_dict(), \"epoch\" : epoch}\n",
        "    save_checkpoint(checkpoint)\n",
        "        \n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "7bc6949f-2d59-44c3-8198-037e115106aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXzW7ASC7ncL"
      },
      "source": [
        "def get_inp_sen_tensor():\n",
        "  sentence = \"Keep your look simple yet stylish by wearing this yellow slim fit long kurta from Fabindia. Tailored to sartorial perfection from premium quality fabric, it assures a soft and soothing touch against the skin. The mandarin collar augments its design. Exuding full sleeves, it is sure to fetch you compliments from all.\"\n",
        "\n",
        "  tokens = tokenizer.tokenize(sentence) #[token for token in sentence]\n",
        "    # Add <SOS> and <EOS> in beginning and end respectively\n",
        "  #print(tokens)\n",
        "  tokens.insert(0, SRC.init_token)\n",
        "  tokens.append(SRC.eos_token)\n",
        "\n",
        "    # Go through each german token and convert to an index\n",
        "  text_to_indices = [SRC.vocab.stoi[token] for token in tokens]\n",
        "  #print(text_to_indices)\n",
        "\n",
        "    # Convert to Tensor\n",
        "  sentence_tensor = torch.LongTensor(text_to_indices).to(device).reshape(1, -1)\n",
        "  #sentence_tensor = batchify(sentence_tensor, 8)\n",
        "\n",
        "  #print(sentence_tensor.shape)\n",
        "\n",
        "  return sentence_tensor\n",
        "    "
      ],
      "id": "SXzW7ASC7ncL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d"
      },
      "source": [
        "def predict(model, input_sequence, max_length=70, SOS_token=2, EOS_token=3):\n",
        "    model.eval()\n",
        "    #itos = SRC.vocab.itos()\n",
        "    \n",
        "    y_input = torch.tensor([[SOS_token]], dtype=torch.long, device=device)\n",
        "    # num_tokens = len(input_sequence[0])\n",
        "    output_sen = []\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        # Get source mask\n",
        "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
        "        \n",
        "        pred = model(input_sequence, y_input, tgt_mask)\n",
        "        \n",
        "        next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
        "        next_item = torch.tensor([[next_item]], device=device)\n",
        "        #print(SRC.vocab.itos[next_item.cpu().detach().numpy()[0][0]])\n",
        "        output_sen.append(TRG.vocab.itos[next_item])\n",
        "\n",
        "        # Concatenate previous input with predicted best word\n",
        "        y_input = torch.cat((y_input, next_item), dim=1)\n",
        "        #print(y_input)\n",
        "\n",
        "        # Stop if model predicts end of sentence\n",
        "        if next_item.view(-1).item() == EOS_token:\n",
        "            break\n",
        "\n",
        "    return ' '.join(output_sen) #y_input.view(-1).tolist()\n",
        "    #vocab.itos(idx)"
      ],
      "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c23630c9-ce84-4996-8d8c-ff7919303331"
      },
      "source": [
        "def validation_loop(model, loss_fn, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            X, y = batch.SPEC.T, batch.PERS.T\n",
        "            # X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n",
        "\n",
        "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
        "            y_input = y[:,:-1]\n",
        "            y_expected = y[:,1:]\n",
        "            \n",
        "            # Get mask to mask out the next words\n",
        "            sequence_length = y_input.size(1)\n",
        "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
        "\n",
        "            # Standard training except we pass in y_input and src_mask\n",
        "            pred = model(X, y_input, tgt_mask)\n",
        "\n",
        "            # Permute pred to have batch size first again\n",
        "            pred = pred.permute(1, 2, 0)      \n",
        "            loss = loss_fn(pred, y_expected)\n",
        "            total_loss += loss.detach().item()\n",
        "\n",
        "    print(predict(model, get_inp_sen_tensor()))\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "id": "c23630c9-ce84-4996-8d8c-ff7919303331",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fd1f633-2e75-422b-af10-52d4fb3618be"
      },
      "source": [
        "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
        "    # Used for plotting later on\n",
        "    train_loss_list, validation_loss_list = [], []\n",
        "    path = %pwd\n",
        "    PATH = os.path.join(path, 'my_checkpoint.pth.tar')\n",
        "    s_epoch = 0\n",
        "    #s_epoch, model, opt = load_checkpoint(PATH, model, opt)\n",
        "\n",
        "    print(\"Training and validating model\")\n",
        "    for epoch in range(s_epoch+1, epochs):\n",
        "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
        "        \n",
        "        train_loss = train_loop(model, opt, loss_fn, train_dataloader, epoch)\n",
        "        writer.add_scalar(\"Training loss\", train_loss, global_step=epoch)\n",
        "        train_loss_list += [train_loss]\n",
        "        \n",
        "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
        "        writer.add_scalar(\"Validation loss\", validation_loss, global_step=epoch)\n",
        "        validation_loss_list += [validation_loss]\n",
        "        \n",
        "        print(f\"Training loss: {train_loss:.4f}\")\n",
        "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
        "        print()\n",
        "        \n",
        "    return train_loss_list, validation_loss_list\n",
        "\n",
        "epochs = 70\n",
        "train_loss_list, validation_loss_list = fit(model, opt, loss_fn, train_iterator, test_iterator, epochs)"
      ],
      "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and validating model\n",
            "------------------------- Epoch 2 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This elegant kurta from Biba will help you maintain an elegant look all year long. you maintain an elegant look all year long. you maintain an elegant look all year long. you maintain an elegant look all year long. you maintain an elegant look all year long. you maintain an elegant look all year long. flats. <eos>\n",
            "Training loss: 1.5815\n",
            "Validation loss: 1.3359\n",
            "\n",
            "------------------------- Epoch 3 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 54.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba will help you maintain an elegant look all year long. you maintain an elegant look all year long. you maintain an elegant look all year long. you maintain an elegant look all year long. you maintain an elegant look all year long. you maintain an elegant look all year long. you maintain an elegant look all year long. Look chic for the day\n",
            "Training loss: 1.3961\n",
            "Validation loss: 1.1793\n",
            "\n",
            "------------------------- Epoch 4 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba will help you maintain an elegant look all year long. Look chic for the day with this kurta and leggings. <eos>\n",
            "Training loss: 1.2617\n",
            "Validation loss: 1.0667\n",
            "\n",
            "------------------------- Epoch 5 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba will help you maintain an elegant look all year long. Look chic for the day with this kurta and leggings. <eos>\n",
            "Training loss: 1.1597\n",
            "Validation loss: 0.9807\n",
            "\n",
            "------------------------- Epoch 6 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba will help you maintain an elegant look all year long. For your next dinner party or family gathering, this kurta set with churidar leggings and chic flats. <eos>\n",
            "Training loss: 1.0776\n",
            "Validation loss: 0.9106\n",
            "\n",
            "------------------------- Epoch 7 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba will take your personal style to new heights. This green piece is a nice family function or event when teamed with churidar leggings and classic flats. <eos>\n",
            "Training loss: 1.0109\n",
            "Validation loss: 0.8556\n",
            "\n",
            "------------------------- Epoch 8 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba will take your personal style to new heights. This green piece is a stylish option for a nice family function or event when teamed with churidar leggings and classic flats. <eos>\n",
            "Training loss: 0.9564\n",
            "Validation loss: 0.8100\n",
            "\n",
            "------------------------- Epoch 9 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 20.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba will take your personal style to new heights. This green piece is a stylish option for a nice family function or event when teamed with churidar leggings and classic flats. <eos>\n",
            "Training loss: 0.9081\n",
            "Validation loss: 0.7674\n",
            "\n",
            "------------------------- Epoch 10 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba will take your personal style to new heights. This green piece is a stylish option for a nice family function or event when teamed with churidar leggings and classic flats. <eos>\n",
            "Training loss: 0.8661\n",
            "Validation loss: 0.7306\n",
            "\n",
            "------------------------- Epoch 11 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba will take your personal style to new heights. This green piece is a stylish option for a nice family function or event when teamed with churidar leggings and classic flats. <eos>\n",
            "Training loss: 0.8297\n",
            "Validation loss: 0.7011\n",
            "\n",
            "------------------------- Epoch 12 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba is a must-have item for any wardrobe. Sport this pink piece with studded flats and minimal jewellery for a simple yet stunning evening ensemble. <eos>\n",
            "Training loss: 0.7996\n",
            "Validation loss: 0.6736\n",
            "\n",
            "------------------------- Epoch 13 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 20.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 54.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba is a must-have item for any wardrobe. Sport this pink piece with studded flats and minimal jewellery for a simple yet stunning evening ensemble. <eos>\n",
            "Training loss: 0.7702\n",
            "Validation loss: 0.6479\n",
            "\n",
            "------------------------- Epoch 14 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 20.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba is a must-have item for any wardrobe. Sport this pink piece with studded flats and minimal jewellery for a simple yet stunning evening ensemble. <eos>\n",
            "Training loss: 0.7425\n",
            "Validation loss: 0.6251\n",
            "\n",
            "------------------------- Epoch 15 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba is a must-have item for any wardrobe. Sport this pink piece with studded flats and minimal jewellery for a simple yet stunning evening ensemble. <eos>\n",
            "Training loss: 0.7189\n",
            "Validation loss: 0.6037\n",
            "\n",
            "------------------------- Epoch 16 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 20.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba is a must-have item for any wardrobe. Sport this pink piece with studded flats and minimal jewellery for a simple yet stunning evening ensemble. <eos>\n",
            "Training loss: 0.6974\n",
            "Validation loss: 0.5828\n",
            "\n",
            "------------------------- Epoch 17 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba is a must-have item for any wardrobe. Sport this pink piece with studded flats and minimal jewellery for a simple yet stunning evening ensemble. <eos>\n",
            "Training loss: 0.6764\n",
            "Validation loss: 0.5655\n",
            "\n",
            "------------------------- Epoch 18 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba is a must-have item for any wardrobe. Sport this pink piece with studded flats and minimal jewellery for a simple yet stunning evening ensemble. <eos>\n",
            "Training loss: 0.6570\n",
            "Validation loss: 0.5505\n",
            "\n",
            "------------------------- Epoch 19 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 312/312 [00:05<00:00, 55.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This breathable and stylish kurta from Biba is a must-have item for any wardrobe. Sport this pink piece with studded flats and minimal jewellery for a simple yet stunning evening ensemble. <eos>\n",
            "Training loss: 0.6394\n",
            "Validation loss: 0.5350\n",
            "\n",
            "------------------------- Epoch 20 -------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1246/1246 [00:59<00:00, 21.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 94/312 [00:01<00:03, 54.72it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-29a3b02bca33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-29a3b02bca33>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, opt, loss_fn, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_loss_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mvalidation_loss_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalidation_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-11805e6f9b0c>\u001b[0m in \u001b[0;36mvalidation_loop\u001b[0;34m(model, loss_fn, dataloader)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_expected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_inp_sen_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40f805ad-7748-4785-9066-c5500287a4af"
      },
      "source": [
        "plt.plot(train_loss_list, label = \"Train loss\")\n",
        "plt.plot(validation_loss_list, label = \"Validation loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "40f805ad-7748-4785-9066-c5500287a4af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybK-TpWA9PhX"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=\"Transformer\""
      ],
      "id": "ybK-TpWA9PhX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSo606ffNEn7"
      },
      "source": [
        "path = %pwd\n",
        "PATH = os.path.join(path, 'my_checkpoint.pth.tar')\n",
        "epoch, model, opt = load_checkpoint(PATH, model, opt)\n",
        "\n",
        "print(SRC.vocab.stoi['<sos>'])\n",
        "print(TRG.vocab.stoi['<sos>'])\n",
        "print(SRC.vocab.stoi['<eos>'])\n",
        "print(TRG.vocab.stoi['<eos>'])\n",
        "print(TRG.vocab)"
      ],
      "id": "fSo606ffNEn7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XoK80AyOn3i"
      },
      "source": [
        "for i in test_iterator:\n",
        "  example = i\n",
        "  #print(example)\n",
        "  X = example.SPEC\n",
        "  print(X.shape)\n",
        "  y = example.PERS\n",
        "  #print(y)\n",
        "  break"
      ],
      "id": "_XoK80AyOn3i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvf2TfdyO_vK"
      },
      "source": [
        "print(predict(model,X[:,0].reshape(1,-1)))#.apply(TRG.vocab.itos()))\n",
        "lol = [] #map(lambda x: TRG.vocab.itos(x), list(y[:,0].cpu().numpy()))\n",
        "next_item = y.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
        "next_item = torch.tensor([[next_item]], device=device)\n",
        "lol.append(TRG.vocab.itos[next_item])\n",
        "print(lol)"
      ],
      "id": "Zvf2TfdyO_vK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD6vGjRMMH8F"
      },
      "source": [
        "predict(model, get_inp_sen_tensor())"
      ],
      "id": "zD6vGjRMMH8F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsJhUMgWrURi"
      },
      "source": [
        "get_inp_sen_tensor()"
      ],
      "id": "fsJhUMgWrURi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItOmWlom8UJM"
      },
      "source": [
        ""
      ],
      "id": "ItOmWlom8UJM",
      "execution_count": null,
      "outputs": []
    }
  ]
}